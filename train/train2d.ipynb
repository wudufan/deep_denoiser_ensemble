{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import shutil\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "import model.unet as unet\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO.datadir = /home/dwu/trainData/deep_denoiser_ensemble/data/mayo_2d_3_layer_mean/\n",
      "IO.manifest = /home/dwu/trainData/deep_denoiser_ensemble/data/mayo_2d_3_layer_mean/manifest.csv\n",
      "IO.outdir = /home/dwu/trainData/deep_denoiser_ensemble/train/mayo_2d_3_layer_mean/\n",
      "IO.train = \n",
      "IO.valid = L291,L143\n",
      "IO.target = dose_rate_1\n",
      "IO.source = dose_rate_4\n",
      "IO.tag = l2_depth_3/debug\n",
      "IO.checkpoint = \n",
      "IO.relog = 1\n",
      "Training.device = 0\n",
      "Training.epoch = 50\n",
      "Training.start_epoch = 0\n",
      "Training.imgshape = 640,640,1\n",
      "Training.batchsize = 2\n",
      "Training.lr = 0.0001\n",
      "Training.save_model_interval = 1\n",
      "Training.output_interval = 10\n",
      "Testing.imgshape = 640,640,1\n",
      "Testing.stepsize = 448,448,1\n",
      "Network.down_features = 64,64,64\n",
      "Network.bottleneck_features = 64\n",
      "Network.up_features = \n",
      "Network.strides = 1,1,1\n",
      "Network.use_adding = 1\n",
      "Network.lrelu = 0.2\n",
      "Augmentation.flipx = 1\n",
      "Augmentation.flipy = 1\n",
      "Window.vmin = -160\n",
      "Window.vmax = 240\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import configparser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', default = './config/baseline/l2_depth_3.cfg')\n",
    "\n",
    "# first get all the params in the cfg\n",
    "args, _ = parser.parse_known_args()\n",
    "cfg = configparser.ConfigParser()\n",
    "cfg.read(args.config)\n",
    "\n",
    "# then add all the parameters in the config to parser\n",
    "for sec in cfg.sections():\n",
    "    for val in cfg[sec]:\n",
    "        parser.add_argument('--%s'%(sec + '.' + val), type=str, default = None)\n",
    "\n",
    "if sys.argv[0] != 'train2d.py':\n",
    "    args = parser.parse_args(['--Training.device', '0', \n",
    "                              '--Training.save_model_interval', '1',\n",
    "#                               '--IO.train', 'L506',\n",
    "                              '--IO.source', 'dose_rate_4', \n",
    "                              '--IO.tag', 'l2_depth_3/debug', \n",
    "                              '--Window.vmin', '-160', \n",
    "                              '--Window.vmax', '240'])\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# update the config\n",
    "for k in vars(args):\n",
    "    val = getattr(args, k)\n",
    "    if val is not None and k != 'config':\n",
    "        sec, key = k.split('.') \n",
    "        cfg[sec][key] = val\n",
    "\n",
    "# output the configuration\n",
    "for sec in cfg.sections():\n",
    "    for val in cfg[sec]:\n",
    "        print ('%s.%s = %s'%(sec, val, cfg[sec][val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = cfg['Training']['device']\n",
    "\n",
    "# make output directory\n",
    "outdir = os.path.join(cfg['IO']['outdir'], cfg['IO']['tag'])\n",
    "logdir = os.path.join(outdir, 'log')\n",
    "valid_dir = os.path.join(outdir, 'valid')\n",
    "if not os.path.exists(valid_dir):\n",
    "    os.makedirs(valid_dir)\n",
    "\n",
    "# clear logdir if needed\n",
    "if int(cfg['IO']['relog']):\n",
    "    if os.path.exists(logdir):\n",
    "        shutil.rmtree(logdir)\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "# save the configuration to output directory\n",
    "with open(os.path.join(outdir, 'config.cfg'), 'w') as f:\n",
    "    cfg.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(filename, manifest, vmin = cfg['Window']['vmin'], vmax = cfg['Window']['vmax']):\n",
    "    img = sitk.GetArrayFromImage(sitk.ReadImage(filename)).astype(np.float32) / 1000\n",
    "    train = img[manifest[manifest.Dataset == 'train'].Index.values][..., np.newaxis]\n",
    "    valid = img[manifest[manifest.Dataset == 'valid'].Index.values][..., np.newaxis]\n",
    "    \n",
    "    try:\n",
    "        vmin = float(vmin) / 1000\n",
    "        vmax = float(vmax) / 1000\n",
    "        \n",
    "        train = (train - vmin) / (vmax - vmin) * 2 - 1\n",
    "        train[train < -1] = -1\n",
    "        train[train > 1] = 1\n",
    "        \n",
    "        valid = (valid - vmin) / (vmax - vmin) * 2 - 1\n",
    "        valid[valid < -1] = -1\n",
    "        valid[valid > 1] = 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    return train, valid\n",
    "\n",
    "def getshape(s):\n",
    "    '''\n",
    "    Convert string \"nx,ny,nz\" to shape [nx,ny,nz]\n",
    "    '''\n",
    "    try:\n",
    "        return [int(i) for i in s.split(',')]\n",
    "    except Exception as _:\n",
    "        return None\n",
    "\n",
    "def augment(img_list, flipx, flipy):\n",
    "    flipx = np.random.randint(0, 2, len(img_list[0])) * flipx\n",
    "    flipy = np.random.randint(0, 2, len(img_list[0])) * flipy\n",
    "    \n",
    "    for i in range(len(img_list)):\n",
    "        for k in range(len(img_list[i])):\n",
    "            if flipx[k]:\n",
    "                img_list[i][k] = img_list[i][k][:, ::-1, :]\n",
    "            if flipy[k]:\n",
    "                img_list[i][k] = img_list[i][k][::-1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...Done\n"
     ]
    }
   ],
   "source": [
    "# manifest\n",
    "manifest = pd.read_csv(cfg['IO']['manifest'])\n",
    "valid_list = cfg['IO']['valid'].split(',')\n",
    "if 'train' not in cfg['IO'] or cfg['IO']['train'] == '':\n",
    "    manifest['Dataset'] = 'train'\n",
    "    manifest.loc[manifest.Tag.isin(valid_list), 'Dataset'] = 'valid'\n",
    "else:\n",
    "    train_list = cfg['IO']['train'].split(',')\n",
    "    manifest.loc[manifest.Tag.isin(valid_list), 'Dataset'] = 'valid'\n",
    "    manifest.loc[manifest.Tag.isin(train_list), 'Dataset'] = 'train'\n",
    "# manifest.loc[manifest.Tag.isin(valid_list), 'Dataset'] = 'valid'\n",
    "\n",
    "# kepp only train and valid\n",
    "manifest = manifest[manifest.Dataset.isin(['train', 'valid'])]\n",
    "assert(len(manifest[manifest.Dataset == 'train']) > 0)\n",
    "\n",
    "manifest.to_csv(os.path.join(outdir, 'manifest.csv'), index=False)\n",
    "\n",
    "# the training list\n",
    "src_list = [os.path.join(cfg['IO']['datadir'], s + '.nii') for s in cfg['IO']['source'].split(',')]\n",
    "dst_list = [os.path.join(cfg['IO']['datadir'], s + '.nii') for s in cfg['IO']['target'].split(',')]\n",
    "\n",
    "# load the dataset\n",
    "print ('Loading', flush=True, end='...')\n",
    "train_y, valid_y = load_img(dst_list[0], manifest)\n",
    "if len(src_list) == 1:\n",
    "    train_x, valid_x = load_img(src_list[0], manifest)\n",
    "print ('Done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "K.clear_session()\n",
    "\n",
    "model_cfg = cfg['Network']\n",
    "model_params = {'down_features': getshape(model_cfg['down_features']), \n",
    "                'up_features': getshape(model_cfg['up_features']), \n",
    "                'bottleneck_features': int(model_cfg['bottleneck_features']), \n",
    "                'lrelu': float(model_cfg['lrelu']), \n",
    "                'strides': getshape(model_cfg['strides']), \n",
    "                'use_adding': int(model_cfg['use_adding'])}\n",
    "\n",
    "imgshape = getshape(cfg['Training']['imgshape'])\n",
    "\n",
    "lr = float(cfg['Training']['lr'])\n",
    "unet_model = unet.unet2d(input_shape = imgshape, output_channel = imgshape[-1], **model_params)\n",
    "model = unet_model.build()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr), loss = tf.keras.losses.mean_squared_error)\n",
    "\n",
    "# tensorboard\n",
    "tb_writer = tf.summary.create_file_writer(logdir)\n",
    "tb_writer.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "checkpoint = cfg['IO']['checkpoint']\n",
    "if os.path.exists(checkpoint):\n",
    "    model.load_weights(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.trace_on(graph = True, profiler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display window\n",
    "try:\n",
    "    vmin = float(cfg['Window']['vmin']) / 1000\n",
    "    vmax = float(cfg['Window']['vmax']) / 1000\n",
    "    \n",
    "    display_vmin = -1\n",
    "    display_vmax = 1\n",
    "except Exception as e:\n",
    "    vmin = -1\n",
    "    vmax = 1\n",
    "    \n",
    "    display_vmin = -0.16\n",
    "    display_vmax = 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1, lr = 0.0001\n",
      "epoch = 1/50, src = 1/1, batch = 10/400, loss = 0.197643\n",
      "epoch = 1/50, src = 1/1, batch = 20/400, loss = 0.176689\n",
      "Validation(1)\n",
      "1: dose_rate_4\n",
      "Starting epoch 2, lr = 0.0001\n",
      "epoch = 2/50, src = 1/1, batch = 10/400, loss = 0.125085\n",
      "epoch = 2/50, src = 1/1, batch = 20/400, loss = 0.100022\n",
      "Validation(1)\n",
      "1: dose_rate_4\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "cfg_train = cfg['Training']\n",
    "nepoch = int(cfg_train['epoch'])\n",
    "start_epoch = int(cfg_train['start_epoch'])\n",
    "batchsize = int(cfg_train['batchsize'])\n",
    "save_model_interval = int(cfg_train['save_model_interval'])\n",
    "output_interval = int(cfg_train['output_interval'])\n",
    "\n",
    "flipx = int(cfg['Augmentation']['flipx'])\n",
    "flipy = int(cfg['Augmentation']['flipy'])\n",
    "\n",
    "train_step = 0\n",
    "for epoch in range(start_epoch, nepoch):\n",
    "    print ('Starting epoch %d, lr = %g'%(epoch+1, lr), flush=True)\n",
    "    \n",
    "    # generate the source dose sequence\n",
    "    sample_src_list = np.copy(src_list)\n",
    "    np.random.shuffle(sample_src_list)\n",
    "    \n",
    "    for isrc in range(len(sample_src_list)):\n",
    "        # read the source image\n",
    "        if len(sample_src_list) > 1:\n",
    "            train_x, valid_x = load_img(sample_src_list[isrc], manifest)\n",
    "        \n",
    "        # generate the slice sequence\n",
    "        islices = np.arange(len(train_x))\n",
    "        np.random.shuffle(islices)\n",
    "        \n",
    "        for i in range(0, len(islices), batchsize):\n",
    "            # sample the slices\n",
    "            inds = islices[i:i+batchsize]\n",
    "            \n",
    "            batch_x = train_x[inds]\n",
    "            batch_y = train_y[inds]\n",
    "            augment([batch_x, batch_y], flipx, flipy)\n",
    "            \n",
    "            loss = model.train_on_batch(batch_x, batch_y)\n",
    "            \n",
    "            if (i//batchsize+1) % output_interval == 0:\n",
    "                print ('epoch = %d/%d, src = %d/%d, batch = %d/%d, loss = %g'%(\n",
    "                    epoch+1, nepoch, \n",
    "                    isrc+1, len(sample_src_list), \n",
    "                    i//batchsize+1, len(islices)//batchsize, \n",
    "                    np.sqrt(loss)), flush=True)\n",
    "\n",
    "            # tensorboard\n",
    "            tf.summary.scalar('train_loss', loss, step = train_step + 1)\n",
    "            if train_step == 0:\n",
    "                tf.summary.trace_export('graph', 1, logdir)\n",
    "            train_step += 1\n",
    "            \n",
    "#             if i >= 50:\n",
    "#                 break\n",
    "        \n",
    "    # save model\n",
    "    model.save(os.path.join(outdir, 'tmp.h5'))\n",
    "    if (epoch + 1) % save_model_interval == 0 or (epoch + 1) == nepoch:\n",
    "        model.save(os.path.join(outdir, '%d.h5'%(epoch+1)))\n",
    "        \n",
    "        print ('Validation(%d)'%(len(src_list)), flush=True)\n",
    "        # validation and testing\n",
    "        l2_losses = []\n",
    "\n",
    "        for isrc in range(len(src_list)): \n",
    "            filename = os.path.basename(src_list[isrc])[:-4]\n",
    "            print ('%d: %s'%(isrc+1, filename), flush=True)\n",
    "            \n",
    "            if len(src_list) > 1:\n",
    "                _, valid_x = load_img(src_list[isrc], manifest)\n",
    "            \n",
    "            preds = model.predict(valid_x, batch_size = 1)\n",
    "            \n",
    "            l2_losses.append(np.sqrt(np.mean((preds - valid_y)**2)))\n",
    "            \n",
    "            # output\n",
    "            tf.summary.image('valid-' + filename + '/pred', utils.snapshot(preds[...,0], len(preds)//2-1, vmin=display_vmin, vmax=display_vmax), step = epoch + 1)\n",
    "            tf.summary.image('valid-' + filename + '/x', utils.snapshot(valid_x[...,0], len(valid_x)//2-1, vmin=display_vmin, vmax=display_vmax), step = epoch + 1)\n",
    "            tf.summary.image('valid-' + filename + '/y', utils.snapshot(valid_y[...,0], len(valid_y)//2-1, vmin=display_vmin, vmax=display_vmax), step = epoch + 1)\n",
    "            tb_writer.flush()\n",
    "            \n",
    "            utils.save_nii(preds[...,0], os.path.join(valid_dir, filename + '.pred.nii'), vmin, vmax)\n",
    "            utils.save_nii(valid_x[...,0], os.path.join(valid_dir, filename + '.x.nii'), vmin, vmax)\n",
    "            utils.save_nii(valid_y[...,0], os.path.join(valid_dir, filename + '.y.nii'), vmin, vmax)\n",
    "        \n",
    "        tf.summary.scalar('valid/loss', np.mean(l2_losses), step = epoch+1)\n",
    "        tb_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
