{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImplementation of wgan_gp\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Implementation of wgan_gp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorResNet2D:\n",
    "    def __init__(self, \n",
    "                 input_shape = [64, 64, 1], \n",
    "                 nconv_per_module = 2, \n",
    "                 features = [64, 128, 256], \n",
    "                 strides = [2, 2, 2],\n",
    "                 fc_features = [1024], \n",
    "                 dropouts = [0.5],\n",
    "                 lrelu = 0.2, \n",
    "                 layer_norm = True):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.nconv_per_module = nconv_per_module\n",
    "        self.features = features\n",
    "        self.strides = strides\n",
    "        self.fc_features = fc_features\n",
    "        self.lrelu = 0.2\n",
    "        self.dropouts = dropouts\n",
    "        self.layer_norm = layer_norm\n",
    "        \n",
    "        assert(len(self.features) == len(self.strides))\n",
    "    \n",
    "    def build(self):\n",
    "        inputs = tf.keras.Input(shape = self.input_shape, name = 'input')\n",
    "        x = inputs\n",
    "        \n",
    "        # residual blocks with downsampling\n",
    "        for i in range(len(self.features)):\n",
    "            # bypass\n",
    "            bypass = tf.keras.layers.Conv2D(self.features[i], 1, strides = self.strides[i], padding = 'same')(x)\n",
    "            # main pass\n",
    "            for k in range(self.nconv_per_module):\n",
    "                if k < self.nconv_per_module - 1:\n",
    "                    x = tf.keras.layers.Conv2D(self.features[i], 3, padding='same')(x)\n",
    "                    if self.layer_norm:\n",
    "                        x = tf.keras.layers.LayerNormalization([1,2,3], scale = False)(x)\n",
    "                    x = tf.keras.layers.LeakyReLU(self.lrelu)(x)\n",
    "                else:\n",
    "                    x = tf.keras.layers.Conv2D(self.features[i], 3, strides = self.strides[i], padding='same')(x)\n",
    "            # merge\n",
    "            x = x + bypass\n",
    "            if self.layer_norm:\n",
    "                x = tf.keras.layers.LayerNormalization([1,2,3], scale = False)(x)\n",
    "            x = tf.keras.layers.LeakyReLU(self.lrelu)(x)\n",
    "        \n",
    "        # fc blocks\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        for i in range(len(self.fc_features)):\n",
    "            x = tf.keras.layers.Dense(self.fc_features[i])(x)\n",
    "            x = tf.keras.layers.LeakyReLU(self.lrelu)(x)\n",
    "            x = tf.keras.layers.Dropout(self.dropouts[i])(x)\n",
    "            \n",
    "        x = tf.keras.layers.Dense(1, use_bias=False)(x)\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs = inputs, outputs = x)\n",
    "        \n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    real_loss = tf.reduce_mean(real_logits)\n",
    "    fake_loss = tf.reduce_mean(fake_logits)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "def generator_loss(fake_logits):\n",
    "    return -tf.reduce_mean(fake_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wgan_gp(tf.keras.Model):\n",
    "    def __init__(self, generator, discriminator, l2_weight = 50, gp_weight = 10, discriminator_steps = 4):\n",
    "        super(wgan_gp, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self._set_inputs(generator.inputs)\n",
    "        self.l2_weight = l2_weight\n",
    "        self.gp_weight = gp_weight\n",
    "        self.d_steps = discriminator_steps\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn = discriminator_loss, g_loss_fn = generator_loss):\n",
    "        super(wgan_gp, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.generator(x)\n",
    "    \n",
    "    def gradient_penalty(self, fake_imgs, real_imgs):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(real_imgs)[0]\n",
    "        \n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_imgs - real_imgs\n",
    "        interpolated = real_imgs + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        \n",
    "        return gp\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 4 steps.\n",
    "        noisy_imgs = data[0]\n",
    "        real_imgs = data[1]\n",
    "        \n",
    "        # the fake_imgs (denoised images) will not change for this batch\n",
    "        fake_imgs = self.generator(noisy_imgs, training=False)\n",
    "        \n",
    "        for i in range(self.d_steps):            \n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_imgs, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_imgs, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_logits=real_logits, fake_logits=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(fake_imgs, real_imgs)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # watch the gradient\n",
    "            fake_imgs = self.generator(noisy_imgs, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(fake_imgs, training=False)\n",
    "            # Calculate the generator loss\n",
    "            g_cost = self.g_loss_fn(gen_img_logits)\n",
    "            # l2 cost\n",
    "            l2_cost = tf.reduce_mean((fake_imgs - real_imgs)**2)\n",
    "            # total generator loss\n",
    "            g_loss = g_cost + l2_cost * self.l2_weight\n",
    "\n",
    "#         print ('gen')\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return {\"d_loss\": d_loss, \"g_cost\": g_cost, \"l2_cost\": l2_cost}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import unet\n",
    "    import os\n",
    "    import tensorflow.keras.backend as K\n",
    "    \n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    K.clear_session()\n",
    "    \n",
    "    gen = unet.unet2d(input_shape = [64,64,1])\n",
    "    g_model = gen.build()\n",
    "    \n",
    "    discriminator = DiscriminatorResNet2D()\n",
    "    d_model = discriminator.build()\n",
    "    \n",
    "    d_optimizer = tf.keras.optimizers.Adam()\n",
    "    g_optimizer = tf.keras.optimizers.Adam()\n",
    "    wgan = wgan_gp(g_model, d_model)\n",
    "    wgan.compile(d_optimizer, g_optimizer)\n",
    "    \n",
    "    img = np.zeros([1,64,64,1], np.float32)\n",
    "    loss = wgan.train_on_batch(img, img, return_dict=True)\n",
    "    \n",
    "#     wgan.save('t', save_format = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
